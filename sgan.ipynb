{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.6 (tensorflow)",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "t81_558_class_07_4_gan_semi_supervised.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTTePv5i4tTS"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/t81_558_class_07_4_gan_semi_supervised.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVAjEdhq4tTY"
      },
      "source": [
        "# GANS for Semi-Supervised Training \n",
        "\n",
        "Semi-Supervised Learning with Generative Adversarial Networks 은 2016년에 소개된 논문이다. \n",
        "\n",
        "GAN 은 준지도 학습으로 사용될 수 있다. 일반적으로 GAN 은 비지도 학습 기법으로 사용이 되는데, 그 이유는 학습데이터의 Ground Truth 가 없기 때문이다. 준지도 학습기법이란 소수의 데이터가 레이블이 달려있거나 그 이외 많은 데이터들이 레이블이 없는 데이터의 쌍을 학습하여서 추론시, Unlabeled 데이터의 라벨링을 예측하는 것을 의미한다.  \n",
        "\n",
        "\n",
        "**Figure 11.TTYPE: Supervised, UnSupervised and Semi-Supervised**\n",
        "![GAN](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/gan-training.png \"GAN\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LIB8azx9SX8"
      },
      "source": [
        "기본적으로 지도학습에서 라베이 안된 데이터는 버려졌지만, 준지도 학습기법에서는 모델의 핵심 목적을 수행하는데 인사이트를 줄 수 있습니다. Semi-supervised GAN 은 분류 문제 또는 회귀 문제 모두 동작합니다. 본 논문에서는 판별자로 하여금 출력의 기능을 하게 함으로써 준지도 기법을 수행합니다. \n",
        "\n",
        "\n",
        "### Semi-Supervised Classification Training\n",
        "\n",
        "Figure 2 는 SGAN 이 분류목적을 어떻게 수행하는 지를 보여줍니다. \n",
        "\n",
        "**Figure 2.GAN-SEMI: GAN for Semisupervised Training**\n",
        "![GAN for Semisupervised Training](https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/images/gan-semi-class.png \"GAN for Semisupervised Training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqo3yj2D9SOk"
      },
      "source": [
        "# example of semi-supervised gan for mnist\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import asarray\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from keras.datasets.mnist import load_data\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Lambda\n",
        "from keras.layers import Activation\n",
        "from matplotlib import pyplot\n",
        "from keras import backend"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTFGnq07Cs-6"
      },
      "source": [
        "본 코드 구현에서는 MNIST handwritten digit dataset 분류를 위한 SGAN 구현을 하도록 하겠습니다. \n",
        "\n",
        "판별자로 stacked discriminator model을 사용할 것입니다. 생성자의 경우 잠재 공간의 인풋 포인트를 입력받고 컨볼루션 레이어를 사용합니다. \n",
        "\n",
        "define_generator() 함수는 생성 모델을 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C78YbGEv-wOq"
      },
      "source": [
        "# define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "\t# image generator input\n",
        "\tin_lat = Input(shape=(latent_dim,))\n",
        "\t# foundation for 7x7 image\n",
        "\tn_nodes = 128 * 7 * 7\n",
        "\tgen = Dense(n_nodes)(in_lat)\n",
        "\tgen = LeakyReLU(alpha=0.2)(gen)\n",
        "\tgen = Reshape((7, 7, 128))(gen)\n",
        "\t# upsample to 14x14\n",
        "\tgen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
        "\tgen = LeakyReLU(alpha=0.2)(gen)\n",
        "\t# upsample to 28x28\n",
        "\tgen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
        "\tgen = LeakyReLU(alpha=0.2)(gen)\n",
        "\t# output\n",
        "\tout_layer = Conv2D(1, (7,7), activation='tanh', padding='same')(gen)\n",
        "\t# define model\n",
        "\tmodel = Model(in_lat, out_layer)\n",
        "\treturn model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ9TqBycBnAz"
      },
      "source": [
        "The define_gan() 함수는 generator 와  discriminator models 을 인풋으로 사용하여, 생성자의 가중치를 훈련시키기 위한 혼합 모델을 Return 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUgu0s1t_CZr"
      },
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\td_model.trainable = False\n",
        "\t# connect image output from generator as input to discriminator\n",
        "\tgan_output = d_model(g_model.output)\n",
        "\t# define gan model as taking noise and outputting a classification\n",
        "\tmodel = Model(g_model.input, gan_output)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCAtmJOl_EAz"
      },
      "source": [
        "# load the images\n",
        "def load_real_samples():\n",
        "\t# load dataset\n",
        "\t(trainX, trainy), (_, _) = load_data()\n",
        "\t# expand to 3d, e.g. add channels\n",
        "\tX = expand_dims(trainX, axis=-1)\n",
        "\t# convert from ints to floats\n",
        "\tX = X.astype('float32')\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX = (X - 127.5) / 127.5\n",
        "\tprint(X.shape, trainy.shape)\n",
        "\treturn [X, trainy]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuJxuU5e_GVg"
      },
      "source": [
        "# select a supervised subset of the dataset, ensures classes are balanced\n",
        "def select_supervised_samples(dataset, n_samples=100, n_classes=10):\n",
        "\tX, y = dataset\n",
        "\tX_list, y_list = list(), list()\n",
        "\tn_per_class = int(n_samples / n_classes)\n",
        "\tfor i in range(n_classes):\n",
        "\t\t# get all images for this class\n",
        "\t\tX_with_class = X[y == i]\n",
        "\t\t# choose random instances\n",
        "\t\tix = randint(0, len(X_with_class), n_per_class)\n",
        "\t\t# add to list\n",
        "\t\t[X_list.append(X_with_class[j]) for j in ix]\n",
        "\t\t[y_list.append(i) for j in ix]\n",
        "\treturn asarray(X_list), asarray(y_list)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlY_jMyN_LGc"
      },
      "source": [
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# split into images and labels\n",
        "\timages, labels = dataset\n",
        "\t# choose random instances\n",
        "\tix = randint(0, images.shape[0], n_samples)\n",
        "\t# select images and labels\n",
        "\tX, labels = images[ix], labels[ix]\n",
        "\t# generate class labels\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn [X, labels], y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjV2tv_i_Mh2"
      },
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tz_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tz_input = z_input.reshape(n_samples, latent_dim)\n",
        "\treturn z_input\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tz_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\timages = generator.predict(z_input)\n",
        "\t# create class labels\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn images, y"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkumh0rIBY5f"
      },
      "source": [
        "\n",
        "The summarize_performance() 매 에폭마다 실행하여 분류 성능을 기록합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Viz8J_lE_Oji"
      },
      "source": [
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, c_model, latent_dim, dataset, n_samples=100):\n",
        "\t# prepare fake examples\n",
        "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\tX = (X + 1) / 2.0\n",
        "\t# plot images\n",
        "\tfor i in range(100):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(10, 10, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'generated_plot_%04d.png' % (step+1)\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        "\t# evaluate the classifier model\n",
        "\tX, y = dataset\n",
        "\t_, acc = c_model.evaluate(X, y, verbose=0)\n",
        "\tprint('Classifier Accuracy: %.3f%%' % (acc * 100))\n",
        "\t# save the generator model\n",
        "\tfilename2 = 'g_model_%04d.h5' % (step+1)\n",
        "\tg_model.save(filename2)\n",
        "\t# save the classifier model\n",
        "\tfilename3 = 'c_model_%04d.h5' % (step+1)\n",
        "\tc_model.save(filename3)\n",
        "\tprint('>Saved: %s, %s, and %s' % (filename1, filename2, filename3))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKT-FPYqA8_P"
      },
      "source": [
        "훈련함수의 배치사이즈는 100, 에폭은 20 으로 초기화하도록 하겠습니다. 준지도 학습 기법의 훈련함수는 거의 vanila GAN 과 비슷하며, 레이블 정보도 함께 학습 시켜 준다는 점이 다릅니다. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPu4K6dr_Qo8"
      },
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, c_model, gan_model, dataset, latent_dim, n_epochs=20, n_batch=100):\n",
        "\t# select supervised dataset\n",
        "\tX_sup, y_sup = select_supervised_samples(dataset)\n",
        "\tprint(X_sup.shape, y_sup.shape)\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# calculate the size of half a batch of samples\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\tprint('n_epochs=%d, n_batch=%d, 1/2=%d, b/e=%d, steps=%d' % (n_epochs, n_batch, half_batch, bat_per_epo, n_steps))\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# update supervised discriminator (c)\n",
        "\t\t[Xsup_real, ysup_real], _ = generate_real_samples([X_sup, y_sup], half_batch)\n",
        "\t\tc_loss, c_acc = c_model.train_on_batch(Xsup_real, ysup_real)\n",
        "\t\t# update unsupervised discriminator (d)\n",
        "\t\t[X_real, _], y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\td_loss1 = d_model.train_on_batch(X_real, y_real)\n",
        "\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\td_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t# update generator (g)\n",
        "\t\tX_gan, y_gan = generate_latent_points(latent_dim, n_batch), ones((n_batch, 1))\n",
        "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\t# summarize loss on this batch\n",
        "\t\tprint('>%d, c[%.3f,%.0f], d[%.3f,%.3f], g[%.3f]' % (i+1, c_loss, c_acc*100, d_loss1, d_loss2, g_loss))\n",
        "\t\t# evaluate the model performance every so often\n",
        "\t\tif (i+1) % (bat_per_epo * 1) == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, c_model, latent_dim, dataset)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6UTMvmzB9P_"
      },
      "source": [
        "본 논문에서는 출력 함수를 명확하게 하기 위하여 활성화 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HWb5kd2CYfN"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBtPLvAy_hqe"
      },
      "source": [
        "# custom activation function\n",
        "def custom_activation(output):\n",
        "\tlogexpsum = backend.sum(backend.exp(output), axis=-1, keepdims=True)\n",
        "\tresult = logexpsum / (logexpsum + 1.0)\n",
        "\treturn result\n",
        " \n",
        "# define the standalone supervised and unsupervised discriminator models\n",
        "def define_discriminator(in_shape=(28,28,1), n_classes=10):\n",
        "\t# image input\n",
        "\tin_image = Input(shape=in_shape)\n",
        "\t# downsample\n",
        "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(in_image)\n",
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n",
        "\t# downsample\n",
        "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n",
        "\t# downsample\n",
        "\tfe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
        "\tfe = LeakyReLU(alpha=0.2)(fe)\n",
        "\t# flatten feature maps\n",
        "\tfe = Flatten()(fe)\n",
        "\t# dropout\n",
        "\tfe = Dropout(0.4)(fe)\n",
        "\t# output layer nodes\n",
        "\tfe = Dense(n_classes)(fe)\n",
        "\t# supervised output\n",
        "\tc_out_layer = Activation('softmax')(fe)\n",
        "\t# define and compile supervised discriminator model\n",
        "\tc_model = Model(in_image, c_out_layer)\n",
        "\tc_model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
        "\t# unsupervised output\n",
        "\td_out_layer = Lambda(custom_activation)(fe)\n",
        "\t# define and compile unsupervised discriminator model\n",
        "\td_model = Model(in_image, d_out_layer)\n",
        "\td_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "\treturn d_model, c_model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PkvsmQgK_S6M",
        "outputId": "23a6759e-fdd6-40e7-952c-090b7d8e2fbc"
      },
      "source": [
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator models\n",
        "d_model, c_model = define_discriminator()\n",
        "# create the generator\n",
        "g_model = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "# train model\n",
        "train(g_model, d_model, c_model, gan_model, dataset, latent_dim)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28, 1) (60000,)\n",
            "(100, 28, 28, 1) (100,)\n",
            "n_epochs=20, n_batch=100, 1/2=50, b/e=600, steps=12000\n",
            ">1, c[2.306,4], d[0.097,2.399], g[0.095]\n",
            ">2, c[2.308,14], d[0.093,2.398], g[0.095]\n",
            ">3, c[2.291,12], d[0.089,2.398], g[0.095]\n",
            ">4, c[2.270,26], d[0.085,2.400], g[0.095]\n",
            ">5, c[2.286,22], d[0.080,2.403], g[0.095]\n",
            ">6, c[2.259,26], d[0.077,2.404], g[0.095]\n",
            ">7, c[2.248,22], d[0.077,2.401], g[0.096]\n",
            ">8, c[2.281,16], d[0.077,2.391], g[0.098]\n",
            ">9, c[2.232,30], d[0.080,2.380], g[0.099]\n",
            ">10, c[2.177,34], d[0.081,2.374], g[0.099]\n",
            ">11, c[2.208,26], d[0.080,2.374], g[0.099]\n",
            ">12, c[2.154,40], d[0.080,2.377], g[0.099]\n",
            ">13, c[2.165,28], d[0.074,2.371], g[0.100]\n",
            ">14, c[2.088,38], d[0.067,2.352], g[0.103]\n",
            ">15, c[2.089,42], d[0.055,2.330], g[0.105]\n",
            ">16, c[2.041,42], d[0.044,2.317], g[0.107]\n",
            ">17, c[2.111,30], d[0.037,2.312], g[0.107]\n",
            ">18, c[2.023,38], d[0.031,2.303], g[0.109]\n",
            ">19, c[1.966,46], d[0.028,2.285], g[0.115]\n",
            ">20, c[1.934,46], d[0.031,2.215], g[0.129]\n",
            ">21, c[1.779,62], d[0.048,2.072], g[0.158]\n",
            ">22, c[1.786,42], d[0.058,1.926], g[0.184]\n",
            ">23, c[1.769,46], d[0.039,1.804], g[0.212]\n",
            ">24, c[1.627,56], d[0.023,1.615], g[0.271]\n",
            ">25, c[1.708,34], d[0.013,1.392], g[0.371]\n",
            ">26, c[1.434,62], d[0.012,1.097], g[0.566]\n",
            ">27, c[1.662,44], d[0.020,0.786], g[0.919]\n",
            ">28, c[1.459,56], d[0.035,0.496], g[1.291]\n",
            ">29, c[1.356,52], d[0.007,0.323], g[1.707]\n",
            ">30, c[1.450,56], d[0.014,0.218], g[2.079]\n",
            ">31, c[1.231,66], d[0.021,0.189], g[2.520]\n",
            ">32, c[1.459,60], d[0.019,0.271], g[4.104]\n",
            ">33, c[1.227,68], d[0.596,0.576], g[0.957]\n",
            ">34, c[1.557,52], d[0.000,2.284], g[2.309]\n",
            ">35, c[1.479,52], d[0.010,0.110], g[4.772]\n",
            ">36, c[1.485,50], d[0.205,0.404], g[4.129]\n",
            ">37, c[1.257,60], d[0.072,0.192], g[4.203]\n",
            ">38, c[1.369,54], d[0.202,0.250], g[3.301]\n",
            ">39, c[1.119,70], d[0.091,0.149], g[3.415]\n",
            ">40, c[1.088,66], d[0.118,0.166], g[3.194]\n",
            ">41, c[1.001,76], d[0.167,0.224], g[3.051]\n",
            ">42, c[1.033,70], d[0.176,0.182], g[3.010]\n",
            ">43, c[1.011,72], d[0.194,0.195], g[3.054]\n",
            ">44, c[0.949,76], d[0.129,0.093], g[3.219]\n",
            ">45, c[1.090,60], d[0.218,0.237], g[2.985]\n",
            ">46, c[1.265,66], d[0.092,0.137], g[3.403]\n",
            ">47, c[1.037,64], d[0.144,0.160], g[3.030]\n",
            ">48, c[0.849,82], d[0.081,0.132], g[3.045]\n",
            ">49, c[0.874,76], d[0.173,0.194], g[2.557]\n",
            ">50, c[0.727,82], d[0.149,0.338], g[2.561]\n",
            ">51, c[1.003,72], d[0.151,0.655], g[2.378]\n",
            ">52, c[0.877,68], d[0.336,1.622], g[1.440]\n",
            ">53, c[0.839,80], d[0.077,1.005], g[3.108]\n",
            ">54, c[1.015,58], d[0.020,0.016], g[5.552]\n",
            ">55, c[1.001,76], d[0.010,0.015], g[4.894]\n",
            ">56, c[0.784,78], d[0.003,0.228], g[2.773]\n",
            ">57, c[0.586,86], d[0.012,1.107], g[3.665]\n",
            ">58, c[1.026,64], d[0.240,0.630], g[6.395]\n",
            ">59, c[0.898,74], d[1.584,2.993], g[2.435]\n",
            ">60, c[0.844,72], d[0.200,0.215], g[4.294]\n",
            ">61, c[0.790,74], d[0.532,0.479], g[2.911]\n",
            ">62, c[0.764,76], d[0.306,0.286], g[2.751]\n",
            ">63, c[0.609,84], d[0.306,0.366], g[2.857]\n",
            ">64, c[0.611,86], d[0.634,0.635], g[2.022]\n",
            ">65, c[0.617,84], d[0.452,0.961], g[1.931]\n",
            ">66, c[0.722,84], d[0.431,0.758], g[2.088]\n",
            ">67, c[0.729,84], d[0.964,1.453], g[1.549]\n",
            ">68, c[0.674,76], d[0.466,0.689], g[2.150]\n",
            ">69, c[0.499,90], d[0.368,0.458], g[2.186]\n",
            ">70, c[0.675,86], d[0.207,0.540], g[1.993]\n",
            ">71, c[0.503,92], d[0.371,0.975], g[1.992]\n",
            ">72, c[0.643,84], d[0.500,1.111], g[2.506]\n",
            ">73, c[0.575,80], d[1.292,1.015], g[1.810]\n",
            ">74, c[0.648,76], d[1.085,0.946], g[1.743]\n",
            ">75, c[0.482,90], d[0.718,0.547], g[1.990]\n",
            ">76, c[0.439,90], d[0.858,0.574], g[1.729]\n",
            ">77, c[0.439,86], d[0.808,0.641], g[1.529]\n",
            ">78, c[0.535,90], d[1.097,0.858], g[1.338]\n",
            ">79, c[0.434,90], d[0.678,0.702], g[1.458]\n",
            ">80, c[0.524,84], d[0.856,0.779], g[1.403]\n",
            ">81, c[0.699,78], d[0.850,0.898], g[1.325]\n",
            ">82, c[0.571,82], d[0.616,0.731], g[1.669]\n",
            ">83, c[0.641,80], d[0.602,0.593], g[1.610]\n",
            ">84, c[0.527,80], d[0.585,0.656], g[1.584]\n",
            ">85, c[0.478,90], d[0.635,0.665], g[1.507]\n",
            ">86, c[0.620,78], d[0.649,0.722], g[1.441]\n",
            ">87, c[0.514,92], d[0.764,0.661], g[1.507]\n",
            ">88, c[0.317,96], d[0.969,0.770], g[1.408]\n",
            ">89, c[0.384,92], d[1.251,0.796], g[1.259]\n",
            ">90, c[0.338,96], d[0.692,0.766], g[1.456]\n",
            ">91, c[0.447,90], d[0.640,0.752], g[1.453]\n",
            ">92, c[0.346,94], d[0.780,0.678], g[1.393]\n",
            ">93, c[0.322,94], d[0.894,0.957], g[1.439]\n",
            ">94, c[0.540,88], d[0.715,0.560], g[1.437]\n",
            ">95, c[0.466,84], d[0.926,0.809], g[1.227]\n",
            ">96, c[0.351,90], d[0.755,0.855], g[1.296]\n",
            ">97, c[0.302,96], d[0.701,0.825], g[1.395]\n",
            ">98, c[0.289,98], d[0.696,0.841], g[1.345]\n",
            ">99, c[0.407,92], d[0.817,0.776], g[1.307]\n",
            ">100, c[0.303,92], d[0.963,0.974], g[1.246]\n",
            ">101, c[0.409,88], d[0.970,0.813], g[1.255]\n",
            ">102, c[0.375,86], d[0.778,0.887], g[1.299]\n",
            ">103, c[0.389,90], d[0.716,0.978], g[1.396]\n",
            ">104, c[0.321,94], d[0.902,0.853], g[1.315]\n",
            ">105, c[0.334,96], d[0.917,0.733], g[1.255]\n",
            ">106, c[0.266,98], d[0.948,0.918], g[1.230]\n",
            ">107, c[0.353,90], d[0.587,0.892], g[1.323]\n",
            ">108, c[0.226,96], d[0.730,0.799], g[1.498]\n",
            ">109, c[0.328,96], d[0.830,0.976], g[1.366]\n",
            ">110, c[0.421,88], d[0.624,1.011], g[1.400]\n",
            ">111, c[0.543,86], d[0.517,0.849], g[1.483]\n",
            ">112, c[0.300,92], d[0.598,0.629], g[1.599]\n",
            ">113, c[0.324,90], d[1.013,0.731], g[1.463]\n",
            ">114, c[0.491,86], d[0.953,0.694], g[1.236]\n",
            ">115, c[0.433,86], d[0.686,0.861], g[1.333]\n",
            ">116, c[0.244,100], d[0.713,0.723], g[1.464]\n",
            ">117, c[0.350,94], d[1.000,0.632], g[1.265]\n",
            ">118, c[0.299,96], d[0.902,0.887], g[1.200]\n",
            ">119, c[0.330,94], d[0.718,0.859], g[1.310]\n",
            ">120, c[0.398,92], d[0.780,0.834], g[1.205]\n",
            ">121, c[0.363,92], d[0.532,0.941], g[1.298]\n",
            ">122, c[0.322,94], d[0.715,0.866], g[1.331]\n",
            ">123, c[0.202,96], d[0.874,0.743], g[1.279]\n",
            ">124, c[0.383,90], d[0.730,0.753], g[1.276]\n",
            ">125, c[0.288,92], d[0.608,0.788], g[1.222]\n",
            ">126, c[0.339,96], d[0.644,0.651], g[1.382]\n",
            ">127, c[0.228,98], d[0.927,0.858], g[1.206]\n",
            ">128, c[0.300,88], d[1.062,0.720], g[1.114]\n",
            ">129, c[0.285,96], d[0.653,0.830], g[1.264]\n",
            ">130, c[0.315,92], d[0.886,0.821], g[1.412]\n",
            ">131, c[0.228,94], d[0.763,0.612], g[1.421]\n",
            ">132, c[0.239,98], d[0.824,0.727], g[1.281]\n",
            ">133, c[0.291,94], d[0.577,0.837], g[1.513]\n",
            ">134, c[0.261,98], d[0.850,0.819], g[1.439]\n",
            ">135, c[0.281,94], d[0.522,0.762], g[1.487]\n",
            ">136, c[0.195,100], d[0.819,0.663], g[1.216]\n",
            ">137, c[0.221,98], d[0.738,0.689], g[1.267]\n",
            ">138, c[0.324,94], d[0.470,0.958], g[1.587]\n",
            ">139, c[0.430,90], d[0.468,0.703], g[1.579]\n",
            ">140, c[0.527,82], d[0.674,0.888], g[1.547]\n",
            ">141, c[0.229,98], d[0.924,0.785], g[1.581]\n",
            ">142, c[0.310,90], d[0.773,0.567], g[1.412]\n",
            ">143, c[0.162,100], d[0.815,0.897], g[1.479]\n",
            ">144, c[0.243,96], d[0.917,0.888], g[1.340]\n",
            ">145, c[0.206,98], d[0.691,0.776], g[1.332]\n",
            ">146, c[0.279,94], d[0.750,0.821], g[1.347]\n",
            ">147, c[0.198,98], d[0.782,0.653], g[1.492]\n",
            ">148, c[0.200,100], d[1.003,0.727], g[1.238]\n",
            ">149, c[0.255,96], d[0.728,0.824], g[1.126]\n",
            ">150, c[0.239,96], d[0.552,0.721], g[1.607]\n",
            ">151, c[0.209,94], d[0.945,0.624], g[1.325]\n",
            ">152, c[0.232,96], d[0.742,0.867], g[1.356]\n",
            ">153, c[0.180,96], d[1.001,0.740], g[1.293]\n",
            ">154, c[0.248,96], d[0.837,0.690], g[1.297]\n",
            ">155, c[0.181,98], d[0.633,0.822], g[1.388]\n",
            ">156, c[0.351,88], d[0.713,0.586], g[1.476]\n",
            ">157, c[0.160,100], d[0.767,0.801], g[1.136]\n",
            ">158, c[0.233,94], d[0.591,0.811], g[1.416]\n",
            ">159, c[0.232,96], d[0.998,0.854], g[1.429]\n",
            ">160, c[0.181,94], d[0.779,0.907], g[1.315]\n",
            ">161, c[0.255,92], d[0.713,0.637], g[1.334]\n",
            ">162, c[0.218,96], d[0.712,0.701], g[1.464]\n",
            ">163, c[0.314,94], d[0.704,1.005], g[1.424]\n",
            ">164, c[0.245,94], d[0.543,0.779], g[1.344]\n",
            ">165, c[0.210,96], d[0.887,0.583], g[1.409]\n",
            ">166, c[0.208,94], d[0.961,0.463], g[1.212]\n",
            ">167, c[0.235,96], d[0.741,0.856], g[1.145]\n",
            ">168, c[0.354,92], d[0.723,0.802], g[1.421]\n",
            ">169, c[0.279,90], d[0.775,0.567], g[1.405]\n",
            ">170, c[0.335,90], d[0.744,0.618], g[1.186]\n",
            ">171, c[0.328,90], d[0.634,0.821], g[1.203]\n",
            ">172, c[0.318,88], d[0.629,1.027], g[1.371]\n",
            ">173, c[0.238,96], d[0.583,0.698], g[1.504]\n",
            ">174, c[0.149,98], d[0.932,0.680], g[1.303]\n",
            ">175, c[0.194,98], d[0.654,0.570], g[1.200]\n",
            ">176, c[0.171,96], d[0.707,0.618], g[1.270]\n",
            ">177, c[0.193,98], d[0.797,0.816], g[1.295]\n",
            ">178, c[0.230,96], d[0.694,0.769], g[1.353]\n",
            ">179, c[0.145,98], d[0.934,0.595], g[1.264]\n",
            ">180, c[0.198,98], d[0.698,0.730], g[1.294]\n",
            ">181, c[0.149,100], d[0.667,0.788], g[1.592]\n",
            ">182, c[0.240,96], d[0.975,0.897], g[1.488]\n",
            ">183, c[0.161,100], d[0.939,0.716], g[1.294]\n",
            ">184, c[0.179,96], d[0.593,0.753], g[1.373]\n",
            ">185, c[0.210,94], d[0.727,0.883], g[1.289]\n",
            ">186, c[0.192,98], d[0.819,0.888], g[1.184]\n",
            ">187, c[0.180,100], d[0.821,0.544], g[1.308]\n",
            ">188, c[0.294,92], d[0.731,0.566], g[1.392]\n",
            ">189, c[0.167,98], d[0.883,0.597], g[1.128]\n",
            ">190, c[0.168,98], d[0.522,0.822], g[1.336]\n",
            ">191, c[0.192,100], d[0.792,0.544], g[1.325]\n",
            ">192, c[0.113,96], d[0.716,0.680], g[1.117]\n",
            ">193, c[0.144,98], d[0.716,0.816], g[1.233]\n",
            ">194, c[0.229,96], d[0.694,0.973], g[1.412]\n",
            ">195, c[0.212,96], d[0.794,0.879], g[1.570]\n",
            ">196, c[0.097,100], d[0.948,0.683], g[1.348]\n",
            ">197, c[0.153,98], d[0.882,0.762], g[1.144]\n",
            ">198, c[0.187,94], d[0.716,0.959], g[1.214]\n",
            ">199, c[0.201,96], d[0.855,0.825], g[1.200]\n",
            ">200, c[0.178,92], d[0.658,0.724], g[1.414]\n",
            ">201, c[0.108,100], d[0.931,0.900], g[1.068]\n",
            ">202, c[0.183,100], d[0.859,0.853], g[1.145]\n",
            ">203, c[0.163,98], d[0.657,1.191], g[1.311]\n",
            ">204, c[0.141,100], d[0.873,0.891], g[1.452]\n",
            ">205, c[0.142,96], d[0.916,0.786], g[1.247]\n",
            ">206, c[0.164,98], d[0.723,0.956], g[1.204]\n",
            ">207, c[0.220,90], d[0.684,1.042], g[1.109]\n",
            ">208, c[0.084,100], d[0.944,0.768], g[1.336]\n",
            ">209, c[0.126,100], d[0.856,1.131], g[1.148]\n",
            ">210, c[0.192,94], d[0.705,0.922], g[1.159]\n",
            ">211, c[0.190,98], d[0.928,0.634], g[1.345]\n",
            ">212, c[0.152,96], d[0.934,0.697], g[1.197]\n",
            ">213, c[0.144,98], d[0.614,0.908], g[1.325]\n",
            ">214, c[0.199,92], d[0.716,0.969], g[1.333]\n",
            ">215, c[0.208,98], d[0.811,0.863], g[1.185]\n",
            ">216, c[0.104,100], d[0.963,0.841], g[1.130]\n",
            ">217, c[0.149,98], d[0.691,0.764], g[1.163]\n",
            ">218, c[0.115,100], d[0.679,0.894], g[1.222]\n",
            ">219, c[0.180,98], d[0.610,0.767], g[1.486]\n",
            ">220, c[0.090,100], d[0.939,0.728], g[1.312]\n",
            ">221, c[0.140,100], d[0.853,0.982], g[1.280]\n",
            ">222, c[0.136,98], d[0.865,0.751], g[1.148]\n",
            ">223, c[0.177,96], d[0.636,0.847], g[1.284]\n",
            ">224, c[0.203,96], d[0.798,0.766], g[1.322]\n",
            ">225, c[0.118,100], d[1.140,0.708], g[1.072]\n",
            ">226, c[0.126,100], d[0.837,0.817], g[1.177]\n",
            ">227, c[0.246,94], d[0.765,1.108], g[1.339]\n",
            ">228, c[0.179,98], d[0.694,0.828], g[1.198]\n",
            ">229, c[0.133,98], d[0.802,0.775], g[1.339]\n",
            ">230, c[0.118,98], d[1.040,0.838], g[1.197]\n",
            ">231, c[0.140,98], d[0.807,0.752], g[1.144]\n",
            ">232, c[0.172,98], d[0.783,0.939], g[1.068]\n",
            ">233, c[0.132,98], d[0.666,0.832], g[1.172]\n",
            ">234, c[0.147,100], d[0.799,0.900], g[1.194]\n",
            ">235, c[0.140,98], d[0.783,0.865], g[1.189]\n",
            ">236, c[0.133,98], d[1.071,1.013], g[1.166]\n",
            ">237, c[0.164,96], d[0.630,0.758], g[1.144]\n",
            ">238, c[0.164,96], d[0.956,0.736], g[1.283]\n",
            ">239, c[0.123,100], d[1.051,0.811], g[1.089]\n",
            ">240, c[0.129,98], d[0.771,1.087], g[1.252]\n",
            ">241, c[0.183,94], d[0.654,1.108], g[1.296]\n",
            ">242, c[0.141,96], d[0.763,0.897], g[1.254]\n",
            ">243, c[0.141,100], d[0.830,0.880], g[1.371]\n",
            ">244, c[0.159,98], d[0.954,0.875], g[1.274]\n",
            ">245, c[0.095,100], d[0.954,0.736], g[1.094]\n",
            ">246, c[0.144,96], d[1.000,0.884], g[1.165]\n",
            ">247, c[0.066,100], d[0.708,0.805], g[1.106]\n",
            ">248, c[0.147,100], d[0.803,0.799], g[1.273]\n",
            ">249, c[0.113,98], d[0.779,0.789], g[1.282]\n",
            ">250, c[0.111,98], d[0.824,0.852], g[1.384]\n",
            ">251, c[0.119,98], d[0.988,0.768], g[1.166]\n",
            ">252, c[0.097,100], d[0.699,0.877], g[1.175]\n",
            ">253, c[0.114,100], d[0.940,0.890], g[1.105]\n",
            ">254, c[0.135,100], d[0.834,0.806], g[1.142]\n",
            ">255, c[0.133,98], d[0.824,0.867], g[1.319]\n",
            ">256, c[0.114,100], d[0.924,0.811], g[1.573]\n",
            ">257, c[0.090,100], d[1.100,0.623], g[1.481]\n",
            ">258, c[0.124,96], d[1.017,0.664], g[1.193]\n",
            ">259, c[0.117,98], d[0.800,0.651], g[1.160]\n",
            ">260, c[0.168,98], d[0.756,0.757], g[1.181]\n",
            ">261, c[0.087,100], d[0.868,0.738], g[1.072]\n",
            ">262, c[0.098,100], d[0.607,0.786], g[1.332]\n",
            ">263, c[0.136,98], d[0.667,0.808], g[1.287]\n",
            ">264, c[0.100,98], d[0.704,0.816], g[1.371]\n",
            ">265, c[0.111,100], d[1.089,0.910], g[1.273]\n",
            ">266, c[0.083,98], d[0.866,1.068], g[1.285]\n",
            ">267, c[0.129,100], d[0.824,0.912], g[1.592]\n",
            ">268, c[0.100,98], d[0.726,0.860], g[1.555]\n",
            ">269, c[0.105,98], d[0.980,0.845], g[1.349]\n",
            ">270, c[0.065,100], d[0.937,0.926], g[1.143]\n",
            ">271, c[0.096,98], d[1.147,0.723], g[1.228]\n",
            ">272, c[0.119,98], d[0.800,0.745], g[1.277]\n",
            ">273, c[0.131,98], d[0.712,0.759], g[1.296]\n",
            ">274, c[0.083,100], d[1.228,0.673], g[1.107]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-40766c111fc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_real_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-028f94a07c50>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, d_model, c_model, gan_model, dataset, latent_dim, n_epochs, n_batch)\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;31m# update generator (g)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mX_gan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_gan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_gan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0;31m# summarize loss on this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>%d, c[%.3f,%.0f], d[%.3f,%.3f], g[%.3f]'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_acc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1725\u001b[0m                                                     class_weight)\n\u001b[1;32m   1726\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMAHYvyf_Jpf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}